{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----+---+----+-----+-----+----+----+---+----+----+----+-------------+-----+\n",
      "|id1|id2|  X|  Y|month|day|FFMC|  DMC|   DC| ISI|temp| RH|wind|rain|fire|month nominal|label|\n",
      "+---+---+---+---+-----+---+----+-----+-----+----+----+---+----+----+----+-------------+-----+\n",
      "|  0|  0|  7|  5|  mar|fri|86.2| 26.2| 94.3| 5.1| 8.2| 51| 6.7| 0.0|   0|            3|    0|\n",
      "|  1|  2|  7|  4|  oct|sat|90.6| 43.7|686.9| 6.7|14.6| 33| 1.3| 0.0|   0|           10|    0|\n",
      "|  2|  3|  8|  6|  mar|fri|91.7| 33.3| 77.5| 9.0| 8.3| 42| 4.0| 0.2|   0|            3|    0|\n",
      "|  3|  4|  8|  6|  mar|sun|89.3| 51.3|102.2| 9.6|11.4| 42| 1.8| 0.0|   0|            3|    0|\n",
      "|  4|  5|  8|  6|  aug|sun|92.3| 85.3|488.0|14.7|22.2| 29| 5.4| 0.0|   0|            8|    0|\n",
      "|  5|  6|  8|  6|  aug|mon|92.3| 88.9|495.6| 8.5|24.1| 27| 3.1| 0.0|   0|            8|    0|\n",
      "|  6|  7|  8|  6|  aug|mon|91.5|145.4|608.2|10.7| 8.0| 42| 2.2| 0.0|   0|            8|    0|\n",
      "|  7|  8|  8|  6|  sep|tue|91.0|129.5|692.6| 7.0|13.1| 63| 5.4| 0.0|   0|            9|    0|\n",
      "|  8|  9|  7|  5|  sep|sat|92.5| 88.0|698.6| 7.1|22.8| 40| 4.0| 0.0|   0|            9|    0|\n",
      "|  9| 10|  7|  5|  sep|sat|92.5| 88.0|698.6| 7.1|17.8| 51| 7.2| 0.0|   0|            9|    0|\n",
      "+---+---+---+---+-----+---+----+-----+-----+----+----+---+----+----+----+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier, LogisticRegression\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler, Normalizer, StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "import pandas as pd\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "spark = SparkSession.builder.appName('transforming').getOrCreate()\n",
    "\n",
    "\n",
    "##### Common to all models's pipeline\n",
    "\n",
    "# Read in data\n",
    "df = spark.read.csv(\"Datasets/forestfires_merged.csv\", inferSchema=True, header=True)\n",
    "df = df.withColumn('label', df.fire)\n",
    "\n",
    "# Create Transformer to deal with categorical values in pipeline\n",
    "indexerDay = StringIndexer(inputCol='day', outputCol='dayIndex')\n",
    "\n",
    "# Create Transformer to convert csv to vector in pipeline\n",
    "vector_assembler = VectorAssembler(inputCols = ['X', 'Y', 'FFMC', 'month nominal', 'dayIndex','DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain'], outputCol = 'features')\n",
    "\n",
    "# Create Transformer to scale values in pipeline\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "\n",
    "# Split the data into training and test sets (20% held out for testing)\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "trainingData.show(10)\n",
    "#df.groupby('fire').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----+---+----+-----+-----+----+----+---+----+----+----+-------------+-----+--------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|id1|id2|  X|  Y|month|day|FFMC|  DMC|   DC| ISI|temp| RH|wind|rain|fire|month nominal|label|dayIndex|            features|      scaledFeatures|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+---+-----+---+----+-----+-----+----+----+---+----+----+----+-------------+-----+--------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| 12| 13|  6|  5|  sep|mon|90.9|126.5|686.5| 7.0|21.3| 42| 2.2| 0.0|   0|            9|    0|     3.0|[6.0,5.0,90.9,9.0...|[2.57132699642860...|[9.05088423273150...|[0.45254421163657...|       1.0|\n",
      "| 13| 14|  6|  5|  sep|wed|92.9|133.3|699.6| 9.2|26.4| 21| 4.5| 0.0|   0|            9|    0|     6.0|[6.0,5.0,92.9,9.0...|[2.57132699642860...|[7.48829805885400...|[0.37441490294270...|       1.0|\n",
      "| 22| 25|  7|  4|  aug|sun|91.4|142.4|601.4|10.6|16.3| 60| 5.4| 0.0|   0|            8|    0|     0.0|[7.0,4.0,91.4,8.0...|[2.99988149583336...|[10.1168781843016...|[0.50584390921508...|       0.0|\n",
      "| 33| 37|  7|  4|  oct|fri|90.0| 41.5|682.6| 8.7|11.3| 60| 5.4| 0.0|   0|           10|    0|     1.0|[7.0,4.0,90.0,10....|[2.99988149583336...|[8.82672217595075...|[0.44133610879753...|       1.0|\n",
      "| 37| 41|  4|  4|  aug|sat|90.2| 96.9|624.2| 8.9|18.4| 42| 6.7| 0.0|   0|            8|    0|     2.0|[4.0,4.0,90.2,8.0...|[1.71421799761906...|[9.44532347603546...|[0.47226617380177...|       1.0|\n",
      "+---+---+---+---+-----+---+----+-----+-----+----+----+---+----+----+----+-------------+-----+--------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+----+--------------------+\n",
      "|prediction|fire|            features|\n",
      "+----------+----+--------------------+\n",
      "|       1.0|   0|[6.0,5.0,90.9,9.0...|\n",
      "|       1.0|   0|[6.0,5.0,92.9,9.0...|\n",
      "|       0.0|   0|[7.0,4.0,91.4,8.0...|\n",
      "|       1.0|   0|[7.0,4.0,90.0,10....|\n",
      "|       1.0|   0|[4.0,4.0,90.2,8.0...|\n",
      "+----------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.669767\n"
     ]
    }
   ],
   "source": [
    "##### Random forest\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"fire\", featuresCol=\"scaledFeatures\")\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=[indexerDay, vector_assembler, scaler, rf])\n",
    "\n",
    "# Train model.  This also runs the other Transformers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "#predictions.show(5)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"fire\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"fire\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------------------+\n",
      "|prediction|fire|            features|\n",
      "+----------+----+--------------------+\n",
      "|       1.0|   0|[6.0,5.0,90.9,9.0...|\n",
      "|       0.0|   0|[6.0,5.0,92.9,9.0...|\n",
      "|       1.0|   0|[7.0,4.0,91.4,8.0...|\n",
      "|       0.0|   0|[7.0,4.0,90.0,10....|\n",
      "|       1.0|   0|[4.0,4.0,90.2,8.0...|\n",
      "+----------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.809302\n"
     ]
    }
   ],
   "source": [
    "##### Gradient Boosted Tree\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"fire\", featuresCol=\"scaledFeatures\")\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline2 = Pipeline(stages=[indexerDay, vector_assembler, scaler, gbt])\n",
    "\n",
    "# Train model.  This also runs the other Transformers.\n",
    "model2 = pipeline2.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions2 = model2.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions2.select(\"prediction\", \"fire\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator2 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"fire\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy2 = evaluator2.evaluate(predictions2)\n",
    "print(\"Accuracy = %g\" % (accuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.809302\n"
     ]
    }
   ],
   "source": [
    "##### Cross validation for Random Forest\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [30]) \\\n",
    "    .addGrid(rf.maxDepth, [20]) \\\n",
    "    .addGrid(rf.minInstancesPerNode, [5]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "\n",
    "cvModel = crossval.fit(trainingData)\n",
    "cvPrediction = cvModel.transform(testData)\n",
    "\n",
    "cvEvaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"fire\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "cvAccuracy = cvEvaluator.evaluate(cvPrediction)\n",
    "print(\"Accuracy = %g\" % (cvAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.911628\n"
     ]
    }
   ],
   "source": [
    "##### Cross Validation for Gradient Boosted Tree\n",
    "paramGrid2 = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [15]) \\\n",
    "    .addGrid(gbt.maxDepth, [10]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [3]) \\\n",
    "    .build()\n",
    "\n",
    "crossval2 = CrossValidator(estimator=pipeline2,\n",
    "                          estimatorParamMaps=paramGrid2,\n",
    "                          evaluator=BinaryClassificationEvaluator(rawPredictionCol='prediction'),\n",
    "                          numFolds=5)\n",
    "\n",
    "cvModel2 = crossval2.fit(trainingData)\n",
    "cvPrediction2 = cvModel2.transform(testData)\n",
    "\n",
    "cvEvaluator2 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"fire\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "cvAccuracy2 = cvEvaluator2.evaluate(cvPrediction2)\n",
    "print(\"Accuracy = %g\" % (cvAccuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvPrediction2.toPandas().to_csv(path_or_buf=\"Datasets/gbt_results_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
